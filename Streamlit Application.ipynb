{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"1LmYSmDjf-OVq0-R9-O5iP_6gUUzM5sAf","authorship_tag":"ABX9TyMlYjBzKz47dds7IThY3aiI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3WMZwfqY0ML","executionInfo":{"status":"ok","timestamp":1735748271903,"user_tz":-120,"elapsed":27759,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}},"outputId":"008fe41a-109f-43fb-bb94-519755ad9624","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n","Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.41.1 watchdog-6.0.0\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.41.1)\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.2\n","Collecting category_encoders\n","  Downloading category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.6.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n","Collecting statsmodels>=0.9.0 (from category_encoders)\n","  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.2.2)\n","Collecting patsy>=0.5.1 (from category_encoders)\n","  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n","Downloading category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: patsy, statsmodels, category_encoders\n","Successfully installed category_encoders-2.6.4 patsy-1.0.1 statsmodels-0.14.4\n","Collecting pulp\n","  Downloading PuLP-2.9.0-py3-none-any.whl.metadata (5.4 kB)\n","Downloading PuLP-2.9.0-py3-none-any.whl (17.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pulp\n","Successfully installed pulp-2.9.0\n","Collecting xgboost\n","  Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n","Collecting nvidia-nccl-cu12 (from xgboost)\n","  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n","Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n","Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.3\n"]}],"source":["!pip install streamlit\n","!pip install streamlit pyngrok\n","!pip install category_encoders\n","!pip install pulp\n","!pip install xgboost"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Mount the drive\n","drive.mount('/content/drive')\n","\n","# Path to the directory\n","project_dir = '/content/drive/MyDrive/Colab Notebooks'\n","\n","# Change the current working directory to this folder\n","os.chdir(project_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RPYcfQ42ell","executionInfo":{"status":"ok","timestamp":1735748285844,"user_tz":-120,"elapsed":13952,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}},"outputId":"1d39d709-9e3a-4de8-cea3-78ae3e69457a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","from io import StringIO\n","import io\n","import plotly.express as px\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","import xgboost as xgb\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Sequential\n","from statsmodels.tsa.ar_model import AutoReg\n","from statsmodels.tsa.stattools import acf, pacf\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from sklearn.ensemble import StackingRegressor\n","from xgboost import XGBRegressor\n","from sklearn.preprocessing import StandardScaler, QuantileTransformer\n","import seaborn as sns\n","import plotly.express as px\n","import category_encoders as ce\n","import math\n","from matplotlib.offsetbox import AnchoredText\n","from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import OneHotEncoder\n","from pulp import LpProblem, LpMinimize, LpVariable, lpSum, LpStatus\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import sys\n","\n","# Function to capture the output of .info() into a string\n","def get_dataframe_info(df):\n","    buffer = StringIO()\n","    df.info(buf=buffer)\n","    return buffer.getvalue()\n","\n","st.title(\"Food Demand Prediction and Optimization App\")\n","st.header(\"1. Upload Your Datasets\")\n","\n","# Upload the three CSV files\n","train_data_file = st.file_uploader(\"Choose the Train Data CSV file\", type=[\"csv\"])\n","fulfilment_center_data_file = st.file_uploader(\"Choose the Fulfilment Center Data CSV file\", type=[\"csv\"])\n","meal_data_file = st.file_uploader(\"Choose the Meal Data CSV file\", type=[\"csv\"])\n","\n","# Check if all three files are uploaded\n","if train_data_file is not None and fulfilment_center_data_file is not None and meal_data_file is not None:\n","    # Load the datasets\n","    train_data = pd.read_csv(train_data_file)\n","    fulfilment_center_data = pd.read_csv(fulfilment_center_data_file)\n","    meal_data = pd.read_csv(meal_data_file)\n","\n","    merged_df = pd.merge(train_data, fulfilment_center_data, on='center_id')\n","    final_merged_df = pd.merge(merged_df, meal_data, on='meal_id')\n","\n","    st.success(\"All files uploaded successfully!\")\n","\n","    st.info(\"For better understanding all datasets were merged into one\")\n","\n","    # Separate Section: Total Demand Time Series\n","    st.header(\"2. Exploratory Data Analysis (EDA)\")\n","\n","    st.subheader(\"Descriptive Statistics\")\n","\n","    # Create a list of options for the user to select\n","    eda_options_descriptive = st.multiselect(\n","        \"Please, select any of the following descriptive processes to perform\",\n","        [\"Preview of the dataset\", \"Show statistics of the dataset\", \"Show any missing values of the dataset\", \"Show dataset information\"]\n","    )\n","\n","    # Perform actions based on the selected EDA option\n","    if \"Preview of the dataset\" in eda_options_descriptive:\n","        st.subheader(\"Merged Dataset Preview\")\n","        st.dataframe(final_merged_df.head())\n","\n","    if \"Show statistics of the dataset\" in eda_options_descriptive:\n","        st.subheader(\"Merged Dataset Statistics\")\n","        st.write(final_merged_df.describe())\n","\n","    if \"Show any missing values of the dataset\" in eda_options_descriptive:\n","        st.subheader(\"Merged Dataset Missing Values\")\n","        st.write(final_merged_df.isna().sum())\n","\n","    if \"Show dataset information\" in eda_options_descriptive:\n","        st.subheader(\"Merged Dataset Information\")\n","        buffer = io.StringIO()\n","        final_merged_df.info(buf=buffer)\n","        info_str = buffer.getvalue()\n","        st.text(info_str)\n","\n","    st.subheader(\"Data Visualization\")\n","\n","    # Create a list of options for the user to select\n","    eda_options_plot = st.multiselect(\n","        \"Please, select any of the following visualization to generate\",\n","        [\"Show the total number of orders time series\", \"Select a center id and a meal id to generate a line plot\"]\n","    )\n","\n","    if \"Show the total number of orders time series\" in eda_options_plot:\n","        st.subheader(\"Total Weekly Number of Orders\")\n","\n","        # Group the data to create a time series\n","        df_plot = final_merged_df.groupby(['week'])['num_orders'].sum().reset_index()\n","\n","        # Create the interactive Plotly line chart\n","        fig = px.line(\n","            df_plot,\n","            x='week',\n","            y='num_orders',\n","            markers=True,\n","            labels={'week': 'Week', 'num_orders': 'Number of Orders'}\n","        )\n","\n","        # Display the plot\n","        st.plotly_chart(fig, use_container_width=True)\n","\n","          # Add a new EDA option for selecting center and meal\n","    if \"Select a center id and a meal id to generate a line plot\" in eda_options_plot:\n","\n","        # Allow the user to select a center\n","        centers = final_merged_df['center_id'].unique()  # Unique center IDs\n","        selected_center = st.selectbox(\"Select a Center ID\", centers)\n","\n","        # Filter the data based on the selected center to get available meals\n","        filtered_data_center = final_merged_df[final_merged_df['center_id'] == selected_center]\n","        meals = filtered_data_center['meal_id'].unique()  # Unique meal IDs for the selected center\n","        selected_meal = st.selectbox(\"Select a Meal ID\", meals)\n","\n","        # Display the selected center and meal in the subheader\n","        st.subheader(f\"Weekly Number of Orders for Center {selected_center} and Meal {selected_meal}\")\n","\n","        # Filter the dataset for the selected center and meal\n","        df_plot_2 = final_merged_df[\n","            (final_merged_df['center_id'] == selected_center) &\n","            (final_merged_df['meal_id'] == selected_meal)\n","        ]\n","\n","        # Create the interactive plot\n","        fig = px.line(\n","            df_plot_2,\n","            x='week',\n","            y='num_orders',\n","            markers=True,\n","            labels={'week': 'Week', 'num_orders': 'Number of Orders'}\n","        )\n","\n","        # Display the plot\n","        st.plotly_chart(fig)\n","\n","\n","    st.subheader(\"Explore Relationships Between Variables\")\n","\n","    # Create a list of options for the user to select\n","    eda_options_relationships = st.multiselect(\n","        \"Please, select any of the following visualizations to discover relationships between features:\",\n","        [\"Create histograms and boxplots\", \"Generate correlation heatmaps and a pair plot\"]\n","    )\n","\n","    # Define numerical features\n","    numerical_features = ['checkout_price', 'base_price', 'num_orders']\n","\n","    if \"Create histograms and boxplots\" in eda_options_relationships:\n","        st.subheader(\"Histogram and Boxplot of the Numerical Features\")\n","\n","        # Create subplots for histograms and box plots\n","        fig, axes = plt.subplots(2, len(numerical_features), figsize=(15, 8))\n","\n","        for i, feature in enumerate(numerical_features):\n","            # Histogram\n","            sns.histplot(final_merged_df[feature], kde=True, ax=axes[0, i])\n","            axes[0, i].set_title(f'Histogram of {feature}')\n","\n","            # Boxplot\n","            sns.boxplot(y=final_merged_df[feature], ax=axes[1, i])\n","            axes[1, i].set_title(f'Boxplot of {feature}')\n","\n","        plt.tight_layout()  # Adjust spacing\n","        st.pyplot(fig)\n","\n","    if \"Generate correlation heatmaps and a pair plot\" in eda_options_relationships:\n","        st.subheader(\"Correlation Heatmap and Pair Plot\")\n","\n","        # Correlation matrices\n","        pearson_corr = final_merged_df[numerical_features].corr(method='pearson')\n","        spearman_corr = final_merged_df[numerical_features].corr(method='spearman')\n","\n","        # Create subplots for correlation heatmaps\n","        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n","\n","        # Pearson correlation heatmap\n","        sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', fmt=\".2f\", ax=axes[0])\n","        axes[0].set_title(\"Pearson Correlation Matrix\")\n","\n","        # Spearman correlation heatmap\n","        sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', fmt=\".2f\", ax=axes[1])\n","        axes[1].set_title(\"Spearman Correlation Matrix\")\n","\n","        plt.tight_layout()\n","        st.pyplot(fig)\n","\n","        # Pair plot\n","        st.write(\"Pair Plot of Numerical Features\")\n","        pairplot_fig = sns.pairplot(final_merged_df[numerical_features], diag_kind='hist', markers=\"o\", height=2.5)\n","        st.pyplot(pairplot_fig.fig)\n","\n","\n","\n","    st.header(\"3. Run XGboost model to predict the number of orders for the last 10 days\")\n","\n","    # Ask the user if they want to run the model\n","    run_model = st.radio(\"Do you want to run the XGBoost model?\", (\"No\", \"Yes\"))\n","\n","    if run_model == \"Yes\":\n","        st.subheader(\"Model Results\")\n","\n","        # Data preparation\n","        df_additional_features = final_merged_df.copy()\n","        df_additional_features['NewCategoryCenter'] = df_additional_features['category'] + '_' + df_additional_features['center_type'].astype(str)\n","        df_additional_features['NewCuisineCenter'] = df_additional_features['cuisine'] + '_' + df_additional_features['center_type'].astype(str)\n","\n","        train_df = df_additional_features[df_additional_features[\"week\"] < 136]\n","        test_df = df_additional_features[df_additional_features[\"week\"] >= 136]\n","        train_df = train_df.copy()\n","        test_df = test_df.copy()\n","        train_df.drop(columns=['id'], inplace=True)\n","        test_df.drop(columns=['id'], inplace=True)\n","\n","        categorical_features = ['center_id', 'meal_id', 'city_code', 'region_code', 'center_type',\n","                                'category', 'cuisine', 'op_area', 'NewCategoryCenter', 'NewCuisineCenter']\n","\n","        one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","        one_hot_encoder.fit(train_df[categorical_features])\n","\n","        train_encoded = one_hot_encoder.transform(train_df[categorical_features])\n","        test_encoded = one_hot_encoder.transform(test_df[categorical_features])\n","\n","        train_encoded_df = pd.DataFrame(train_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_features), index=train_df.index)\n","        test_encoded_df = pd.DataFrame(test_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_features), index=test_df.index)\n","\n","        train_df_encoded = pd.concat([train_df.drop(columns=categorical_features), train_encoded_df], axis=1)\n","        test_df_encoded = pd.concat([test_df.drop(columns=categorical_features), test_encoded_df], axis=1)\n","\n","        X_train, y_train = train_df_encoded.drop(columns=['num_orders']), train_df_encoded['num_orders']\n","        X_test, y_test = test_df_encoded.drop(columns=['num_orders']), test_df_encoded['num_orders']\n","\n","        # Convert to DMatrix format\n","        dtrain = xgb.DMatrix(X_train, label=y_train)\n","        dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","        # XGBoost model training\n","        xgb_params = {\n","            'objective': 'reg:squarederror',\n","            'tree_method': 'hist',\n","            'eval_metric': 'rmse',\n","            'device': 'cuda',  # Adjust based on availability\n","            'learning_rate': 0.1,\n","            'max_depth': 7,\n","            'random_state': 42\n","        }\n","        xgb_regressor = xgb.train(xgb_params, dtrain, num_boost_round=200)\n","\n","        # Predictions\n","        y_pred = xgb_regressor.predict(dtest)\n","\n","        # Calculate metrics\n","        mse = mean_squared_error(y_test, y_pred)\n","        rmse = mse ** 0.5\n","        mae = mean_absolute_error(y_test, y_pred)\n","        mape = (abs((y_test - y_pred) / y_test).mean()) * 100\n","        r2 = r2_score(y_test, y_pred)\n","\n","        # Create a DataFrame for metrics\n","        metrics_data = {\n","            \"Metric\": [\n","                \"Mean Absolute Error (MAE)\",\n","                \"Mean Absolute Percentage Error (MAPE)\",\n","                \"Root Mean Squared Error (RMSE)\",\n","                \"R² Score\"\n","            ],\n","            \"Value\": [\n","                f\"{mae:.2f}\",\n","                f\"{mape:.2f}%\",\n","                f\"{rmse:.2f}\",\n","                f\"{r2:.2f}\"\n","            ]\n","        }\n","        metrics_df = pd.DataFrame(metrics_data)\n","\n","        # Display the results\n","        st.table(metrics_df)\n","\n","    elif run_model == \"No\":\n","        st.write(\"You chose not to run the model.\")\n","\n","    # Add an option to ask the user if they want to run the optimization model\n","    st.header(\"4. Optimization Model\")\n","\n","    # Prompt the user\n","    run_optimization = st.radio(\"Do you want to run the optimization model?\", (\"No\", \"Yes\"))\n","\n","    if run_optimization == \"Yes\":\n","        if run_model != \"Yes\":\n","            st.error(\"You need to run the XGBoost model first to use the optimization model.\")\n","        else:\n","            # Create a variable to store the test_df\n","            data = test_df.copy()\n","\n","            # Convert the y_pred variable from numpy array to pandas Series\n","            y_pred_series = pd.Series(y_pred, index=data.index, name='predicted')\n","\n","            # Concatenate the test data with actual and predicted values\n","            data = pd.concat([data, y_pred_series], axis=1)\n","\n","            # Drop the actual 'num_orders' column and reorder the columns\n","            data.drop(['num_orders'], axis=1, inplace=True)\n","            data = data[['week', 'center_id', 'meal_id', 'checkout_price', 'predicted']]\n","\n","            # Step 1: Display available center IDs\n","            centers = data['center_id'].unique()\n","\n","            # Step 2: User selects centers\n","            selected_centers = st.multiselect(\"Select the center IDs to include:\", centers)\n","            if not selected_centers:\n","                st.warning(\"Please select at least one center to proceed.\")\n","            else:\n","                # Filter data for selected centers\n","                filtered_data_center = data[data['center_id'].isin(selected_centers)]\n","\n","                # Step 3: Find common meals across selected centers\n","                center_meals = filtered_data_center.groupby('center_id')['meal_id'].unique()\n","\n","                common_meals = set(center_meals.iloc[0])  # Start with meals from the first center\n","                for meals in center_meals[1:]:\n","                    common_meals &= set(meals)  # Keep only meals that are common to all centers\n","\n","                # Convert the common meals back to a list for user selection\n","                common_meals = list(common_meals)\n","\n","                # Step 4: User selects meals\n","                selected_meals = st.multiselect(\"Select the meal IDs to include:\", common_meals)\n","                if not selected_meals:\n","                    st.warning(\"Please select at least one meal to proceed.\")\n","                else:\n","                    # Function to check meal availability over 10 weeks\n","                    def is_meal_available_for_10_weeks(meal_id, center_id, data):\n","                        filtered_data = data[(data['meal_id'] == meal_id) &\n","                                            (data['center_id'] == center_id) &\n","                                            (data['week'] >= 136) &\n","                                            (data['week'] <= 145)]\n","                        return len(filtered_data['week'].unique()) >= 10\n","\n","                    # Step 5: Validate meal availability\n","                    valid_meals = []\n","                    invalid_meals_details = []\n","\n","                    for meal in selected_meals:\n","                        invalid_centers = [center for center in selected_centers if not is_meal_available_for_10_weeks(meal, center, filtered_data_center)]\n","                        if not invalid_centers:\n","                            valid_meals.append(meal)\n","                        else:\n","                            invalid_meals_details.append({'meal': meal, 'invalid_centers': invalid_centers})\n","\n","                    # Display invalid meals and their centers\n","                    if invalid_meals_details:\n","                        st.error(\"Some selected meals do not contain last 10 weeks for predicting period.\")\n","                        for detail in invalid_meals_details:\n","                            st.write(f\"Meal: {detail['meal']} is not valid in centers: {detail['invalid_centers']}\")\n","                    else:\n","                        st.success(\"All selected meals are valid in all centers.\")\n","\n","                    # Step 6: Ask user to proceed with valid meals\n","                    if valid_meals:\n","                        proceed = st.radio(f\"Do you want to proceed with the valid meals {valid_meals}?\", [\"No\", \"Yes\"])\n","                        if proceed == \"Yes\":\n","                            # Filter data for valid meals\n","                            filtered_data_meal = filtered_data_center[filtered_data_center['meal_id'].isin(valid_meals)]\n","\n","                            selected_meals = valid_meals\n","\n","                            # Collect ordering, holding, and unit costs for each meal\n","                            ordering_cost = {}\n","                            holding_cost = {}\n","                            unit_cost = {}\n","\n","                            st.subheader(\"Enter Costs for Each Meal\")\n","\n","                            for meal_id in selected_meals:\n","                                st.markdown(f\" #### Meal ID {meal_id}\")\n","                                ordering_cost[meal_id] = st.number_input(f\"Enter ordering cost for Meal {meal_id}:\", min_value=0.0, step=0.01)\n","                                holding_cost[meal_id] = st.number_input(f\"Enter holding cost per unit for Meal {meal_id}:\", min_value=0.0, step=0.01)\n","                                unit_cost[meal_id] = st.number_input(f\"Enter unit cost for Meal {meal_id}:\", min_value=0.0, step=0.01)\n","\n","                            # Create dictionaries for demand and checkout price, indexed by meal_id and week\n","                            demand = {}\n","                            checkout_price = {}\n","\n","                            for center_id in selected_centers:\n","                                center_data = filtered_data_meal[filtered_data_meal['center_id'] == center_id]  # Filter data for the center\n","\n","                                demand_temp = {}\n","                                checkout_price_temp = {}\n","\n","                                for meal_id in selected_meals:\n","                                    meal_data = center_data[center_data['meal_id'] == meal_id]  # Filter data for the meal\n","\n","                                    # Store predicted demand and checkout prices for each week\n","                                    demand_temp[meal_id] = meal_data['predicted'].tolist()\n","                                    checkout_price_temp[meal_id] = meal_data['checkout_price'].tolist()\n","\n","                                demand[center_id] = demand_temp\n","                                checkout_price[center_id] = checkout_price_temp\n","\n","                            weeks = list(range(1, len(filtered_data_meal['week'].unique().tolist()) + 1))  # List of weeks\n","                            meals = selected_meals\n","                            centers = selected_centers\n","\n","                            # Define baseline budget using realistic weekly demand\n","                            baseline_budget = {}\n","                            margin = 1.2  # Additional margin to account for extra costs\n","\n","                            for center in centers:\n","                                total_demand_cost = 0\n","                                for meal in meals:\n","                                    weekly_demand = demand[center][meal]  # Predicted demand per week\n","                                    for t, demand_value in enumerate(weekly_demand):\n","                                        total_demand_cost += unit_cost[meal] * demand_value\n","                                baseline_budget[center] = total_demand_cost / (len(weeks) - 1) * margin  # Adjusted with margin\n","\n","                            # Display calculated baseline budgets\n","                            st.subheader(\"Baseline Budget Suggestion with 1.2 Margin\")\n","                            for center, budget_value in baseline_budget.items():\n","                                st.write(f\"Center {center}: {budget_value:.2f}\")\n","\n","                            # Collect user-defined budget and warehouse capacity for each center\n","                            budget = {}\n","                            warehouse_capacity = {}\n","                            initial_inventory = {}\n","\n","                            st.subheader(\"Enter Budget and Warehouse Capacity\")\n","\n","                            for center_id in selected_centers:\n","                                st.markdown(f\"#### Center ID {center_id}\")\n","                                budget[center_id] = st.number_input(f\"Enter the weekly budget for center {center_id}:\", min_value=0.0, step=0.01)\n","                                warehouse_capacity[center_id] = st.number_input(f\"Enter the warehouse capacity for center {center_id}:\", min_value=0, step=1)\n","\n","                                initial_inventory_temp = {}\n","                                for meal_id in selected_meals:\n","                                    initial_inventory_temp[meal_id] = st.number_input(\n","                                        f\"Enter initial inventory for Meal {meal_id} in center {center_id}:\", min_value=0, step=1\n","                                    )\n","\n","                                initial_inventory[center_id] = initial_inventory_temp\n","\n","                            # Define lead time\n","                            lead_time = 1\n","\n","                            # Ensure `selected_meals`, `selected_centers`, `demand`, `checkout_price`, `unit_cost`, `ordering_cost`, `holding_cost`, `budget`, and `warehouse_capacity` are defined.\n","\n","                            # Define the optimization problem\n","\n","                            prob = LpProblem(\"Multiple_Centers_Meals_Optimization\", LpMinimize)\n","\n","                            # Decision variables\n","                            order_qty = LpVariable.dicts(\"Order\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                            inventory = LpVariable.dicts(\"Inventory\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                            order_indicator = LpVariable.dicts(\"OrderIndicator\", (centers, meals, weeks), cat=\"Binary\")\n","                            unmet_demand = LpVariable.dicts(\"UnmetDemand\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","\n","                            # Objective function: Minimize ordering, holding, and penalty costs\n","                            prob += lpSum(\n","                                ordering_cost[meal] * order_indicator[center][meal][t] +\n","                                order_qty[center][meal][t] * unit_cost[meal] +\n","                                holding_cost[meal] * inventory[center][meal][t] +\n","                                checkout_price[center][meal][t-1] * unmet_demand[center][meal][t]\n","                                for center in centers for meal in meals for t in weeks\n","                            )\n","\n","                            # Constraints\n","                            for center in centers:\n","                                for t in weeks:\n","                                    for meal in meals:\n","                                        # Inventory balance constraint\n","                                        if t == 1:\n","                                            prob += inventory[center][meal][t] == initial_inventory[center][meal] - demand[center][meal][t-1] + unmet_demand[center][meal][t]\n","                                        else:\n","                                            prob += inventory[center][meal][t] == inventory[center][meal][t-1] + order_qty[center][meal][t-lead_time] - demand[center][meal][t-1] + unmet_demand[center][meal][t] - unmet_demand[center][meal][t-1]\n","\n","                                        # Link binary variable to order quantity using Big-M method\n","                                        prob += order_qty[center][meal][t] <= 1000000 * order_indicator[center][meal][t]\n","\n","                                    # Weekly budget constraint\n","                                    prob += lpSum(order_qty[center][meal][t] * unit_cost[meal] + ordering_cost[meal] * order_indicator[center][meal][t] for meal in meals) <= budget[center]\n","\n","                                    # Warehouse capacity constraint\n","                                    prob += lpSum(inventory[center][meal][t] for meal in meals) <= warehouse_capacity[center]\n","\n","                            # Solve the problem\n","                            with st.spinner(\"Solving the problem...\"):\n","                                prob.solve()\n","\n","                            # Check solution status\n","                            solution_status = LpStatus[prob.status]\n","                            st.write(f\"Solution Status: {solution_status}\")\n","\n","                            # Collect results\n","                            results = []\n","                            for center in centers:\n","                                for meal in meals:\n","                                    for t in weeks:\n","                                        results.append({\n","                                            \"Center\": center,\n","                                            \"Week\": t,\n","                                            \"Meal\": meal,\n","                                            \"Order\": order_qty[center][meal][t].varValue,\n","                                            \"Inventory\": inventory[center][meal][t].varValue,\n","                                            \"Unmet Demand\": unmet_demand[center][meal][t].varValue\n","                                        })\n","\n","                            results_df = pd.DataFrame(results)\n","                            st.subheader(\"Optimization Results\")\n","                            st.dataframe(results_df)\n","\n","                            # Metrics Calculation\n","                            total_ordering_cost = 0\n","                            total_holding_cost = 0\n","                            total_penalty_cost = 0\n","                            total_unmet_demand = 0\n","                            unmet_demand_frequency = 0\n","                            budget_utilization = {}\n","\n","                            for center in centers:\n","                                center_spending = 0  # Total spending for the center\n","                                for meal in meals:\n","                                    unmet_demand_value = unmet_demand[center][meal][len(weeks)].varValue\n","                                    total_unmet_demand += unmet_demand_value\n","\n","                                    for t in weeks:\n","                                        order_cost = ordering_cost[meal] * order_indicator[center][meal][t].varValue + order_qty[center][meal][t].varValue * unit_cost[meal]\n","                                        holding_cost_week = holding_cost[meal] * inventory[center][meal][t].varValue\n","                                        penalty_cost_week = checkout_price[center][meal][t-1] * unmet_demand[center][meal][t].varValue\n","\n","                                        total_ordering_cost += order_cost\n","                                        total_holding_cost += holding_cost_week\n","                                        total_penalty_cost += penalty_cost_week\n","\n","                                        if unmet_demand[center][meal][t].varValue > 0:\n","                                            unmet_demand_frequency += 1\n","\n","                                        center_spending += order_cost\n","\n","                                budget_utilization[center] = round(center_spending / (budget[center] * (len(weeks) - 1)), 2)\n","\n","                            evaluation_results = {\n","                                \"Total Cost\": total_ordering_cost + total_holding_cost + total_penalty_cost,\n","                                \"Ordering Cost\": total_ordering_cost,\n","                                \"Holding Cost\": total_holding_cost,\n","                                \"Penalty Cost\": total_penalty_cost,\n","                                \"Total Unmet Demand\": total_unmet_demand,\n","                                \"Unmet Demand Frequency\": unmet_demand_frequency,\n","                                \"Budget Utilization\": budget_utilization\n","                            }\n","\n","                            evaluation_results = pd.DataFrame(evaluation_results)\n","                            st.subheader(\"Evaluation Metrics\")\n","                            st.dataframe(evaluation_results)\n","\n","\n","                            st.subheader(\"Visualization Plot\")\n","                            # Get unique centers and meals\n","                            unique_centers = results_df[\"Center\"].unique()\n","                            unique_meals = results_df[\"Meal\"].unique()\n","\n","                            # Use a qualitative color palette for more distinct colors\n","                            color_palette = px.colors.qualitative.Plotly\n","                            num_colors = len(color_palette)\n","                            color_mapping = {meal: color_palette[i % num_colors] for i, meal in enumerate(unique_meals)}\n","\n","                            # Create subplots: 1 column per center\n","                            num_rows = 1\n","                            num_cols = len(unique_centers)\n","                            fig = make_subplots(\n","                                rows=num_rows,\n","                                cols=num_cols,\n","                                subplot_titles=[f\"Center {center}\" for center in unique_centers],\n","                                shared_xaxes=True,\n","                            )\n","\n","                            # Plot data for each center\n","                            for i, center in enumerate(unique_centers):\n","                                center_data = results_df[results_df[\"Center\"] == center]\n","                                for meal in unique_meals:\n","                                    meal_data = center_data[center_data[\"Meal\"] == meal]\n","\n","                                    # Ensure legendgroup is a string\n","                                    legend_group = str(meal)\n","\n","                                    # Add bars for unmet demand\n","                                    fig.add_trace(\n","                                        go.Bar(\n","                                            x=meal_data[\"Week\"],\n","                                            y=meal_data[\"Unmet Demand\"],\n","                                            name=f\"Unmet Demand for {meal}\",\n","                                            marker=dict(color=color_mapping[meal], opacity=0.6),\n","                                            legendgroup=legend_group,\n","                                            showlegend=(i == 0),  # Show legend only once per meal\n","                                        ),\n","                                        row=1,\n","                                        col=i + 1,\n","                                    )\n","\n","                                    # Add lines for order quantities\n","                                    fig.add_trace(\n","                                        go.Scatter(\n","                                            x=meal_data[\"Week\"],\n","                                            y=meal_data[\"Order\"],\n","                                            mode=\"lines+markers\",\n","                                            name=f\"Order Quantity for {meal}\",\n","                                            line=dict(width=2, color=color_mapping[meal]),\n","                                            legendgroup=legend_group,\n","                                            showlegend=(i == 0),  # Show legend only once per meal\n","                                        ),\n","                                        row=1,\n","                                        col=i + 1,\n","                                    )\n","\n","                            # Update layout\n","                            fig.update_layout(\n","                                title=\"Order Quantities and Unmet Demand Over Time by Meal and Center\",\n","                                xaxis_title=\"Weeks\",\n","                                yaxis_title=\"Order Quantity And Unmet Demand\",\n","                                height=600,\n","                                legend_title=\"Legend\",\n","                                template=\"plotly\"\n","                            )\n","\n","                            # Display the figure in Streamlit\n","                            st.plotly_chart(fig, use_container_width=True)\n","\n","                            st.subheader(\"Sensitivity Analysis\")\n","\n","                            # Ask user if they want to perform sensitivity analysis\n","                            proceed = st.radio(f\"Do you want to perform a Sensitivity Analysis?\", [\"No\", \"Yes\"])\n","                            if proceed == \"Yes\":\n","                                # Ask for budget reduction levels\n","                                reduction_input = st.text_input(\"Enter budget reduction percentage levels (comma-separated):\", \"10,20,30\")\n","\n","                                if reduction_input:\n","                                    try:\n","                                        # Parse the reduction levels\n","                                        budget_reduction_levels = [float(budget.strip()) for budget in reduction_input.split(\",\")]\n","\n","                                        # Store results for sensitivity analysis\n","                                        sensitivity_results = []\n","\n","                                        # Loop over budget reduction levels\n","                                        for reduction in budget_reduction_levels:\n","                                            # Adjust budget\n","                                            adjusted_budget = {center: budget[center] * (1 - reduction / 100) for center in centers}\n","\n","                                            # Initialize LP problem\n","                                            prob = LpProblem(\"Multiple_Centers_Meals_Optimization\", LpMinimize)\n","\n","                                            # Decision variables\n","                                            order_qty = LpVariable.dicts(\"Order\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                                            inventory = LpVariable.dicts(\"Inventory\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                                            order_indicator = LpVariable.dicts(\"OrderIndicator\", (centers, meals, weeks), cat=\"Binary\")\n","                                            unmet_demand = LpVariable.dicts(\"UnmetDemand\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","\n","                                            # Objective function\n","                                            prob += lpSum(\n","                                                ordering_cost[meal] * order_indicator[center][meal][t] +\n","                                                order_qty[center][meal][t] * unit_cost[meal] +\n","                                                holding_cost[meal] * inventory[center][meal][t] +\n","                                                checkout_price[center][meal][t-1] * unmet_demand[center][meal][t]\n","                                                for center in centers for meal in meals for t in weeks\n","                                            )\n","\n","                                            # Constraints\n","                                            for center in centers:\n","                                                for t in weeks:\n","                                                    for meal in meals:\n","                                                        # Inventory balance constraint\n","                                                        if t == 1:\n","                                                            prob += inventory[center][meal][t] == initial_inventory[center][meal] - demand[center][meal][t-1] + unmet_demand[center][meal][t]\n","                                                        else:\n","                                                            if t - lead_time > 0:\n","                                                                prob += inventory[center][meal][t] == inventory[center][meal][t-1] + order_qty[center][meal][t-lead_time] - demand[center][meal][t-1] + unmet_demand[center][meal][t] - unmet_demand[center][meal][t-1]\n","                                                            else:\n","                                                                prob += inventory[center][meal][t] == inventory[center][meal][t-1] - demand[center][meal][t-1] + unmet_demand[center][meal][t] - unmet_demand[center][meal][t-1]\n","\n","                                                        # Link binary variable to order quantity\n","                                                        prob += order_qty[center][meal][t] <= 1000000 * order_indicator[center][meal][t]\n","\n","                                                    # Weekly budget constraint with adjusted budget\n","                                                    prob += lpSum(order_qty[center][meal][t] * unit_cost[meal] + ordering_cost[meal] * order_indicator[center][meal][t] for meal in meals) <= adjusted_budget[center]\n","\n","                                                    # Warehouse capacity constraint\n","                                                    prob += lpSum(inventory[center][meal][t] for meal in meals) <= warehouse_capacity[center]\n","\n","                                            # Solve the optimization problem\n","                                            prob.solve()\n","\n","                                            # Calculate evaluation metrics\n","                                            total_ordering_cost = 0\n","                                            total_holding_cost = 0\n","                                            total_penalty_cost = 0\n","                                            total_unmet_demand = 0\n","                                            unmet_demand_frequency = 0\n","                                            budget_utilization = {}\n","\n","                                            for center in centers:\n","                                                center_spending = 0\n","                                                for meal in meals:\n","                                                    unmet_demand_value = unmet_demand[center][meal][len(weeks)].varValue\n","                                                    total_unmet_demand += unmet_demand_value\n","\n","                                                    for t in weeks:\n","                                                        order_cost = ordering_cost[meal] * order_indicator[center][meal][t].varValue + order_qty[center][meal][t].varValue * unit_cost[meal]\n","                                                        holding_cost_week = holding_cost[meal] * inventory[center][meal][t].varValue\n","                                                        penalty_cost_week = checkout_price[center][meal][t-1] * unmet_demand[center][meal][t].varValue\n","\n","                                                        total_ordering_cost += order_cost\n","                                                        total_holding_cost += holding_cost_week\n","                                                        total_penalty_cost += penalty_cost_week\n","\n","                                                        if unmet_demand[center][meal][t].varValue > 0:\n","                                                            unmet_demand_frequency += 1\n","\n","                                                        center_spending += order_cost\n","\n","                                                budget_utilization[center] = round(center_spending / (adjusted_budget[center] * (len(weeks) - 1)), 2)\n","\n","                                            # Store results for this reduction level\n","                                            sensitivity_results.append({\n","                                                \"Reduction %\": reduction,\n","                                                \"Total Cost\": total_ordering_cost + total_holding_cost + total_penalty_cost,\n","                                                \"Ordering Cost\": total_ordering_cost,\n","                                                \"Holding Cost\": total_holding_cost,\n","                                                \"Penalty Cost\": total_penalty_cost,\n","                                                \"Total Unmet Demand\": total_unmet_demand,\n","                                                \"Unmet Demand Frequency\": unmet_demand_frequency,\n","                                                \"Budget Utilization\": budget_utilization\n","                                            })\n","\n","                                        # Convert results to DataFrame\n","                                        sensitivity_df = pd.DataFrame(sensitivity_results)\n","\n","                                        # Display results\n","                                        st.write(\"Sensitivity Analysis Results:\")\n","                                        st.dataframe(sensitivity_df)\n","\n","                                        # Extracting data from the results DataFrame for plot\n","                                        x = sensitivity_df[\"Reduction %\"]\n","                                        ordering = sensitivity_df[\"Ordering Cost\"]\n","                                        holding = sensitivity_df[\"Holding Cost\"]\n","                                        penalty = sensitivity_df[\"Penalty Cost\"]\n","                                        total_unmet = sensitivity_df[\"Total Unmet Demand\"]\n","\n","                                        # Create a Plotly figure\n","                                        fig = go.Figure()\n","\n","                                        # Add traces for cost components (primary y-axis)\n","                                        fig.add_trace(go.Scatter(x=x, y=ordering, mode=\"lines+markers\", name=\"Ordering Cost\", line=dict(color=\"skyblue\")))\n","                                        fig.add_trace(go.Scatter(x=x, y=holding, mode=\"lines+markers\", name=\"Holding Cost\", line=dict(color=\"green\", dash=\"dash\")))\n","                                        fig.add_trace(go.Scatter(x=x, y=penalty, mode=\"lines+markers\", name=\"Penalty Cost\", line=dict(color=\"orange\", dash=\"dot\")))\n","\n","                                        # Add a trace for unmet demand (secondary y-axis)\n","                                        fig.add_trace(go.Scatter(x=x, y=total_unmet, mode=\"lines+markers\", name=\"Unmet Demand\", line=dict(color=\"red\"), yaxis=\"y2\"))\n","\n","                                        # Update layout for dual y-axes\n","                                        fig.update_layout(\n","                                            title=\"Cost Components and Unmet Demand vs Budget Reduction\",\n","                                            xaxis=dict(title=\"Budget Reduction (%)\"),\n","                                            yaxis=dict(title=\"Costs\", titlefont=dict(color=\"black\"), tickfont=dict(color=\"black\")),\n","                                            yaxis2=dict(\n","                                                title=\"Unmet Demand\",\n","                                                titlefont=dict(color=\"red\"),\n","                                                tickfont=dict(color=\"red\"),\n","                                                anchor=\"x\",\n","                                                overlaying=\"y\",\n","                                                side=\"right\",\n","                                            ),\n","                                            legend=dict(x=0.5, y=-0.2, orientation=\"h\"),\n","                                            template=\"plotly_white\",\n","                                        )\n","\n","                                        # Display the plot\n","                                        st.plotly_chart(fig)\n","\n","\n","                                    except ValueError:\n","                                        st.error(\"Please enter valid numeric values for budget reduction levels.\")\n","                            else:\n","                                st.write(\"You chose not to run a sensitivity analysis.\")\n","\n","                            st.subheader(\"Simulation Analysis\")\n","                            # Ask the user if they want to perform a simulation analysis\n","                            perform_simulation = st.radio(\"Do you want to perform a simulation analysis?\", (\"No\", \"Yes\"))\n","\n","                            if perform_simulation == \"Yes\":\n","                                # Input fields for scenarios and simulation number\n","                                simulation_scenario_input = st.text_input(\"Enter demand scenarios with a decimal point (e.g., 0.1, 0.2):\")\n","                                simulation_number_input = st.number_input(\"Enter the number of simulations for each scenario:\", min_value=1, step=1)\n","\n","                                if simulation_scenario_input and simulation_number_input:\n","                                    # Parse inputs\n","                                    simulation_scenario = [float(s.strip()) for s in simulation_scenario_input.split(\",\")]\n","                                    simulation_number = int(simulation_number_input)\n","\n","                                    simulated_datasets = []\n","\n","                                    # Simulate demand for each scenario\n","                                    for scenario in simulation_scenario:\n","                                        for i in range(simulation_number):\n","                                            simulated_data = filtered_data_meal.copy()\n","                                            simulated_data['predicted'] = simulated_data['predicted'] * (\n","                                                1 + np.random.uniform(-scenario, scenario, len(filtered_data_meal))\n","                                            )\n","                                            simulated_data['scenario'] = f\"Scenario: {scenario*100:.0f}% | Sim {i+1}\"\n","                                            simulated_datasets.append(simulated_data)\n","\n","                                    # Combine simulated datasets\n","                                    simulated_data_full = pd.concat(simulated_datasets, ignore_index=True)\n","\n","                                    # Placeholder for storing simulation results\n","                                    simulation_results = []\n","\n","                                    # Optimization loop for each scenario\n","                                    for scenario, scenario_data in simulated_data_full.groupby('scenario'):\n","                                        # Prepare demand data for the scenario\n","                                        demand = {\n","                                            center: {\n","                                                meal: scenario_data[\n","                                                    (scenario_data['center_id'] == center) & (scenario_data['meal_id'] == meal)\n","                                                ]['predicted'].tolist()\n","                                                for meal in meals\n","                                            }\n","                                            for center in centers\n","                                        }\n","\n","                                        # Initialize LP problem\n","                                        prob = LpProblem(\"Simulation_Optimization\", LpMinimize)\n","\n","                                        # Decision variables\n","                                        order_qty = LpVariable.dicts(\"Order\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                                        inventory = LpVariable.dicts(\"Inventory\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","                                        order_indicator = LpVariable.dicts(\"OrderIndicator\", (centers, meals, weeks), cat=\"Binary\")\n","                                        unmet_demand = LpVariable.dicts(\"UnmetDemand\", (centers, meals, weeks), lowBound=0, cat=\"Integer\")\n","\n","                                        # Objective function: Minimize ordering + holding + penalty costs\n","                                        prob += lpSum(\n","                                            ordering_cost[meal] * order_indicator[center][meal][t] +\n","                                            order_qty[center][meal][t] * unit_cost[meal] +\n","                                            holding_cost[meal] * inventory[center][meal][t] +\n","                                            checkout_price[center][meal][t-1] * unmet_demand[center][meal][t]\n","                                            for center in centers for meal in meals for t in weeks\n","                                        )\n","\n","                                        # Constraints\n","                                        for center in centers:\n","                                            for t in weeks:\n","                                                for meal in meals:\n","                                                    # Inventory balance constraint\n","                                                    if t == 1:\n","                                                        prob += inventory[center][meal][t] == initial_inventory[center][meal] - demand[center][meal][t-1] + unmet_demand[center][meal][t]\n","                                                    else:\n","                                                        if t - lead_time > 0:\n","                                                            prob += inventory[center][meal][t] == inventory[center][meal][t-1] + order_qty[center][meal][t-lead_time] - demand[center][meal][t-1] + unmet_demand[center][meal][t] - unmet_demand[center][meal][t-1]\n","                                                        else:\n","                                                            prob += inventory[center][meal][t] == inventory[center][meal][t-1] - demand[center][meal][t-1] + unmet_demand[center][meal][t] - unmet_demand[center][meal][t-1]\n","\n","                                                    # Link binary variable to order quantity\n","                                                    prob += order_qty[center][meal][t] <= 1000000 * order_indicator[center][meal][t]\n","\n","                                                # Weekly budget constraint\n","                                                prob += lpSum(order_qty[center][meal][t] * unit_cost[meal] + ordering_cost[meal] * order_indicator[center][meal][t] for meal in meals) <= budget[center]\n","\n","                                                # Warehouse capacity constraint\n","                                                prob += lpSum(inventory[center][meal][t] for meal in meals) <= warehouse_capacity[center]\n","\n","                                        # Solve the optimization problem\n","                                        prob.solve()\n","\n","                                        # Collect metrics\n","                                        total_ordering_cost = 0\n","                                        total_holding_cost = 0\n","                                        total_penalty_cost = 0\n","                                        total_unmet_demand = 0\n","                                        unmet_demand_frequency = 0\n","                                        budget_utilization = {}\n","\n","                                        for center in centers:\n","                                            center_spending = 0\n","                                            for meal in meals:\n","                                                unmet_demand_value = unmet_demand[center][meal][len(weeks)].varValue\n","                                                total_unmet_demand += unmet_demand_value\n","\n","                                                for t in weeks:\n","                                                    order_cost = ordering_cost[meal] * order_indicator[center][meal][t].varValue + order_qty[center][meal][t].varValue * unit_cost[meal]\n","                                                    holding_cost_week = holding_cost[meal] * inventory[center][meal][t].varValue\n","                                                    penalty_cost_week = checkout_price[center][meal][t-1] * unmet_demand[center][meal][t].varValue\n","\n","                                                    total_ordering_cost += order_cost\n","                                                    total_holding_cost += holding_cost_week\n","                                                    total_penalty_cost += penalty_cost_week\n","\n","                                                    if unmet_demand[center][meal][t].varValue > 0:\n","                                                        unmet_demand_frequency += 1\n","\n","                                                    center_spending += order_cost\n","\n","                                            budget_utilization[center] = round(center_spending / (budget[center] * (len(weeks) - 1)), 2)\n","\n","                                        # Store results for this simulation scenario\n","                                        simulation_results.append({\n","                                            \"Scenario\": scenario,\n","                                            \"Total Cost\": total_ordering_cost + total_holding_cost + total_penalty_cost,\n","                                            \"Ordering Cost\": total_ordering_cost,\n","                                            \"Holding Cost\": total_holding_cost,\n","                                            \"Penalty Cost\": total_penalty_cost,\n","                                            \"Total Unmet Demand\": total_unmet_demand,\n","                                            \"Unmet Demand Frequency\": unmet_demand_frequency,\n","                                            \"Budget Utilization\": budget_utilization\n","                                        })\n","\n","                                    # Convert to DataFrame and display results\n","                                    simulation_df = pd.DataFrame(simulation_results)\n","                                    st.write(\"### Simulation Analysis Results\")\n","                                    st.dataframe(simulation_df)\n","\n","\n","                                    # Extract relevant columns\n","                                    simulation_plot_data = simulation_df[['Scenario', 'Unmet Demand Frequency']]\n","\n","                                    # Extract variation type from the scenario string\n","                                    simulation_plot_data['Scenario'] = simulation_plot_data['Scenario'].apply(lambda x: x.split(' | ')[0])\n","\n","                                    # Group by Variation and calculate the mean unmet demand frequency\n","                                    grouped_data = simulation_plot_data.groupby('Scenario')['Unmet Demand Frequency'].mean().reset_index()\n","\n","                                    # Create an interactive line plot using Plotly\n","                                    fig = px.line(\n","                                        grouped_data,\n","                                        x='Scenario',\n","                                        y='Unmet Demand Frequency',\n","                                        title='Unmet Demand Frequency by Scenario',\n","                                        labels={'Scenario': 'Scenario', 'Unmet Demand Frequency': 'Average Unmet Demand Frequency'},\n","                                        markers=True\n","                                    )\n","\n","                                    # Update layout for better readability\n","                                    fig.update_layout(\n","                                        xaxis=dict(title='Scenario', tickangle=45),\n","                                        yaxis=dict(title='Average Unmet Demand Frequency'),\n","                                        title=dict(font=dict(size=14)),\n","                                        template='plotly_white'\n","                                    )\n","\n","\n","                                    # Render the plot in Streamlit\n","                                    st.plotly_chart(fig)\n","\n","                            else:\n","                                st.write(\"You chose not to run the simulation analysis\")\n","\n","                    else:\n","                            st.warning(\"Exiting as per user request.\")\n","\n","    elif run_optimization == \"No\":\n","        st.write(\"You chose not to run the optimization model.\")\n","\n","else:\n","    st.warning(\"Please upload all three datasets to proceed.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqTEVOp5xpQn","executionInfo":{"status":"ok","timestamp":1735748286266,"user_tz":-120,"elapsed":431,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}},"outputId":"87f9e8d7-0e12-485e-8e63-ff5028751c0f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!ngrok config add-authtoken 2kX3tK3R9TjwVlAeb9xO5KooTeG_3ZAw4tmGFojLrkxRw8gEs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zRo37vM1XhI","executionInfo":{"status":"ok","timestamp":1735748287585,"user_tz":-120,"elapsed":1328,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}},"outputId":"d1fda502-f312-4f28-fe9c-cd3bfafb061c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":["import subprocess\n","from pyngrok import ngrok\n","import os\n","import time\n","\n","# Function to stop any previous ngrok processes and the Streamlit app\n","def stop_streamlit_and_ngrok():\n","    try:\n","        # Stop ngrok processes if any\n","        os.system(\"pkill ngrok\")\n","        print(\"ngrok processes stopped.\")\n","\n","        # Terminate Streamlit processes if any\n","        os.system(\"pkill -f streamlit\")\n","        print(\"Streamlit processes stopped.\")\n","\n","    except Exception as e:\n","        print(f\"Error stopping processes: {e}\")\n","\n","# Function to restart Streamlit app\n","def restart_streamlit_app():\n","    # Stop any running processes first\n","    stop_streamlit_and_ngrok()\n","\n","    # Wait for a second to ensure processes have stopped\n","    time.sleep(1)\n","\n","    # Start the Streamlit app\n","    streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n","\n","    # Create a public URL for the Streamlit app\n","    public_url = ngrok.connect(8501)\n","    print(f\"Streamlit app is live at: {public_url}\")\n","\n","# Call the function to restart the Streamlit app\n","restart_streamlit_app()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqEctjJY0No7","executionInfo":{"status":"ok","timestamp":1735748289015,"user_tz":-120,"elapsed":1437,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}},"outputId":"ed31c4d9-7cb4-4702-88be-a343f612138e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ngrok processes stopped.\n","Streamlit processes stopped.\n","Streamlit app is live at: NgrokTunnel: \"https://d0dd-35-226-28-129.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":["!pip freeze > requirements.txt\n"],"metadata":{"id":"bz4WjDsm7BPq","executionInfo":{"status":"ok","timestamp":1735748873402,"user_tz":-120,"elapsed":620,"user":{"displayName":"Christos Galanis","userId":"10285972895748632697"}}},"execution_count":7,"outputs":[]}]}